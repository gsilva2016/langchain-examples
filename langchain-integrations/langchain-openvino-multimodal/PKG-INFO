Metadata-Version: 2.3
Name: langchain-openvino-multimodal
Version: 0.1.1
Summary: An integration package connecting OpenVINOMultimodal and LangChain
License: MIT
Requires-Python: >=3.9,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Requires-Dist: langchain-community (>=0.3.23,<0.4.0)
Requires-Dist: langchain-core (>=0.3.15,<0.4.0)
Requires-Dist: langchain-huggingface (>=0.1.2,<0.2.0)
Requires-Dist: torch (>=2.7.0,<3.0.0)
Requires-Dist: torchvision (>=0.22.0,<0.23.0)
Requires-Dist: transformers (==4.48.0)
Project-URL: Repository, https://github.com/langchain-ai/langchain
Project-URL: Release Notes, https://github.com/langchain-ai/langchain/releases?q=tag%3A%22openvino-multimodal%3D%3D0%22&expanded=true
Project-URL: Source Code, https://github.com/langchain-ai/langchain/tree/master/libs/partners/openvino-multimodal
Description-Content-Type: text/markdown

# langchain-openvino-multimodal

This package contains the LangChain integration with OpenVINOClip, and OpenVINOBgeEmbeddings

## Installation

```bash
pip install -U langchain-openvino-multimodal
```

## Embeddings

This class includes the two OpenVINO classes from `langchain_community.embeddings.openvino`. These classes were inlcuded for a unified class to create all types of OpenVINO embeddings from a single langchain package. 

For sample usage, Please see - [Usage](https://python.langchain.com/docs/integrations/text_embedding/openvino/)
1. `OpenVINOEmbeddings`
2. `OpenVINOBgeEmbeddings`

This package includes a new class for OpenVINO CLIP embeddings (images and text) called `OpenVINOClipEmbeddings` class.

```python
from langchain_openvino_multimodal import OpenVINOClipEmbeddings

# Default model is: "openai/clip-vit-base-patch32" and Default device is GPU.
# Possible device values for Image embeddings are "CPU, GPU, NPU".
# Possible device values for Text embeddings are "CPU, GPU". NPU is not supported.
embeddings = OpenvinoClipEmbeddings(
                model_id="openai/clip-vit-base-patch32",
                device="GPU",
            )

# Embed single text:
input_text = "A photo of a cat"
embed.embed_query(input_text)

# Embed multiple text:
input_texts = ["text 1...", "text 2..."]
embed.embed_documents(input_texts)

# Embed single image:
input_image = "path/to/image.jpg"
embed.embed_image(input_image)

# Embed multiple images:
input_images = ["path/to/image1.jpg", "path/to/image2.jpg"]
embed.embed_images(input_images)
```

